{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "44cf59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\axbae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\axbae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Error loading stopord: Package 'stopord' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Script to Extract tweets of a \n",
    "# particular Hashtag using Tweepy and Pandas\n",
    "\n",
    "# import modules\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import datetime\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import preprocessor as p\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet') \n",
    "nltk.download('stop') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c47d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "    print()\n",
    "    print(f\"Tweet {n}:\")\n",
    "    print(f\"Username:{ith_tweet[0]}\")\n",
    "    print(f\"Description:{ith_tweet[1]}\")\n",
    "    print(f\"Location:{ith_tweet[2]}\")\n",
    "    print(f\"Following Count:{ith_tweet[3]}\")\n",
    "    print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "    print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "    print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "    print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "    print(f\"Hashtags Used:{ith_tweet[8]}\")\n",
    "    print(f\"Date:{ith_tweet[9]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4d1138b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importer dansk som sprog\n",
    "#pip install afinn\n",
    "from afinn import Afinn\n",
    "afinn = Afinn(language='da')\n",
    "afinn.score('Hvis ikke det er det mest afskyelige flueknepperi...')\n",
    "-6.0\n",
    "\n",
    "#user = api.get_status(id)\n",
    "  \n",
    "# fetching the created_at attribute\n",
    "#created_at = status.created_at \n",
    "\n",
    "#today = datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d934155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter HashTag to search for\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-83e8c7d0e330>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# Enter Hashtag and initial date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter Twitter HashTag to search for\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter Date since The Tweets are required in yyyy-mm--dd\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mdate_since\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    "      \n",
    "    # Creating DataFrame using pandas\n",
    "    db = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
    "                               'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags', 'date'])\n",
    "      \n",
    "    # We are using .Cursor() to search through twitter for the required tweets.\n",
    "    # The number of tweets can be restricted using .items(number of tweets)\n",
    "    tweets = tweepy.Cursor(api.search, q=words, lang=\"da\",\n",
    "                           since=date_since, tweet_mode='extended').items(numtweet)\n",
    "     \n",
    "    # .Cursor() returns an iterable object. Each item in \n",
    "    # the iterator has various attributes that you can access to \n",
    "    # get information about each tweet\n",
    "    list_tweets = [tweet for tweet in tweets]\n",
    "      \n",
    "    # Counter to maintain Tweet Count\n",
    "    i = 1  \n",
    "      \n",
    "    # we will iterate over each tweet in the list for extracting information about each tweet\n",
    "    for tweet in list_tweets:\n",
    "        username = tweet.user.screen_name\n",
    "        description = tweet.user.description\n",
    "        location = tweet.user.location\n",
    "        following = tweet.user.friends_count\n",
    "        followers = tweet.user.followers_count\n",
    "        totaltweets = tweet.user.statuses_count\n",
    "        retweetcount = tweet.retweet_count\n",
    "        hashtags = tweet.entities['hashtags']\n",
    "        date = tweet.created_at\n",
    "          \n",
    "        # Retweets can be distinguished by a retweeted_status attribute,\n",
    "        # in case it is an invalid reference, except block will be executed\n",
    "        try:\n",
    "            text = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            text = tweet.full_text\n",
    "        hashtext = list()\n",
    "        for j in range(0, len(hashtags)):\n",
    "            hashtext.append(hashtags[j]['text'])\n",
    "          \n",
    "        # Here we are appending all the extracted information in the DataFrame\n",
    "        ith_tweet = [username, description, location, following,\n",
    "                     followers, totaltweets, retweetcount, text, hashtext, date]\n",
    "        db.loc[len(db)] = ith_tweet\n",
    "        \n",
    "          \n",
    "        # Function call to print tweet data on screen\n",
    "        printtweetdata(i, ith_tweet)\n",
    "        i = i+1\n",
    "    filename = 'df3.csv'\n",
    "      \n",
    "    # we will save our database as a CSV file.\n",
    "    db.to_csv(filename)\n",
    "  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "      \n",
    "    # Enter your own credentials obtained \n",
    "    # from your developer account\n",
    "    consumer_key = \"HlgemqHuJ83L0NkQbg4rZQLQ1\"\n",
    "    consumer_secret = \"iT2MPE5T2n4pGqDlTbFsStnlPyRPgOvk64bEhdRA7ZTE86G60g\"\n",
    "    access_key = \"1427158064092876800-MNinx9VxTMhQf07xIutt2upLZvAaPn\"\n",
    "    access_secret = \"Utlu32drsCwKj3SnCAYU2qKZ66VNovYBxLxdRu4DeDWrA\"\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "      \n",
    "    # Enter Hashtag and initial date\n",
    "    print(\"Enter Twitter HashTag to search for\")\n",
    "    words = input()\n",
    "    print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "    date_since = input()\n",
    "      \n",
    "    # number of tweets you want to extract in one run\n",
    "    numtweet = 10000\n",
    "    scrape(words, date_since, numtweet)\n",
    "    print('Scraping has completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd255c",
   "metadata": {},
   "source": [
    "### Combining dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db839c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SupAyaLaya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1228</td>\n",
       "      <td>521</td>\n",
       "      <td>34115</td>\n",
       "      <td>1</td>\n",
       "      <td>Beder alle indberette dette tweet, da det tyde...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-16 23:59:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mullarrd</td>\n",
       "      <td>Nearsighted scrap pile, perpetual lefty. Searc...</td>\n",
       "      <td>Pangaea</td>\n",
       "      <td>515</td>\n",
       "      <td>536</td>\n",
       "      <td>39951</td>\n",
       "      <td>17</td>\n",
       "      <td>Få din vaccination uden tidsbestilling. Der er...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-16 21:14:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>GitteKJP</td>\n",
       "      <td>Søger viden, nyheder og indsigter til eftertanke.</td>\n",
       "      <td>København</td>\n",
       "      <td>972</td>\n",
       "      <td>947</td>\n",
       "      <td>231239</td>\n",
       "      <td>17</td>\n",
       "      <td>Få din vaccination uden tidsbestilling. Der er...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-16 16:41:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>idamariehansen7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nykøbing Sjælland</td>\n",
       "      <td>1292</td>\n",
       "      <td>346</td>\n",
       "      <td>21549</td>\n",
       "      <td>17</td>\n",
       "      <td>Få din vaccination uden tidsbestilling. Der er...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-16 16:07:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ThomasHeie</td>\n",
       "      <td>Fængselsbetjent - FREM'er - Fotograf - FDFer</td>\n",
       "      <td>København, Danmark</td>\n",
       "      <td>111</td>\n",
       "      <td>269</td>\n",
       "      <td>21567</td>\n",
       "      <td>0</td>\n",
       "      <td>Indsatsen i Afghanistan har kostet Danmark 15 ...</td>\n",
       "      <td>['dkpol', 'COVID19dk']</td>\n",
       "      <td>2021-08-16 15:48:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>26</td>\n",
       "      <td>KlausKblog</td>\n",
       "      <td>Klaus K, journalist &amp; sangskriver i Danser med...</td>\n",
       "      <td>København</td>\n",
       "      <td>511</td>\n",
       "      <td>2464</td>\n",
       "      <td>33254</td>\n",
       "      <td>28</td>\n",
       "      <td>Israels massevaccination: \\n25% stigning i hje...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-11 18:48:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>27</td>\n",
       "      <td>HettingClaus</td>\n",
       "      <td>\"Three things remain not long hidden: The Sun,...</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2249</td>\n",
       "      <td>2717</td>\n",
       "      <td>15616</td>\n",
       "      <td>28</td>\n",
       "      <td>Israels massevaccination: \\n25% stigning i hje...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021-08-11 17:59:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>28</td>\n",
       "      <td>nbm_1981</td>\n",
       "      <td>IT Automation Consultant (MCAAA/MCSA/MCP). Lik...</td>\n",
       "      <td>København, Danmark</td>\n",
       "      <td>612</td>\n",
       "      <td>624</td>\n",
       "      <td>12430</td>\n",
       "      <td>28</td>\n",
       "      <td>Israels massevaccination: \\n25% stigning i hje...</td>\n",
       "      <td>['dkpol', 'dkmedier', 'coronadk', 'covid19dk',...</td>\n",
       "      <td>2021-08-11 17:50:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>29</td>\n",
       "      <td>transceiverfreq</td>\n",
       "      <td>xi=aixi'-(d+ai0+ai1)xi+rxi(fi-Φ ) | Freelance ...</td>\n",
       "      <td>Frederiksberg, Denmark</td>\n",
       "      <td>339</td>\n",
       "      <td>1089</td>\n",
       "      <td>44893</td>\n",
       "      <td>0</td>\n",
       "      <td>@DRNyheder @tv2newsdk @moderna_tx @pfizer Jeg ...</td>\n",
       "      <td>['dkpol', 'dkmedier', 'COVID19']</td>\n",
       "      <td>2021-08-10 19:29:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>30</td>\n",
       "      <td>CirkuzE</td>\n",
       "      <td>Cirkuz Pol-Etik Et samfunds satirisk program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>Kan man få en klima-vaccine?? Så er @Spolitik ...</td>\n",
       "      <td>['dkpol', 'dkmedier', 'COVID19dk', 'coronadk',...</td>\n",
       "      <td>2021-08-09 16:41:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1736 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0         username  \\\n",
       "0              0       SupAyaLaya   \n",
       "1              1         Mullarrd   \n",
       "2              2         GitteKJP   \n",
       "3              3  idamariehansen7   \n",
       "4              4       ThomasHeie   \n",
       "...          ...              ...   \n",
       "1731          26       KlausKblog   \n",
       "1732          27     HettingClaus   \n",
       "1733          28         nbm_1981   \n",
       "1734          29  transceiverfreq   \n",
       "1735          30          CirkuzE   \n",
       "\n",
       "                                            description  \\\n",
       "0                                                   NaN   \n",
       "1     Nearsighted scrap pile, perpetual lefty. Searc...   \n",
       "2     Søger viden, nyheder og indsigter til eftertanke.   \n",
       "3                                                   NaN   \n",
       "4          Fængselsbetjent - FREM'er - Fotograf - FDFer   \n",
       "...                                                 ...   \n",
       "1731  Klaus K, journalist & sangskriver i Danser med...   \n",
       "1732  \"Three things remain not long hidden: The Sun,...   \n",
       "1733  IT Automation Consultant (MCAAA/MCSA/MCP). Lik...   \n",
       "1734  xi=aixi'-(d+ai0+ai1)xi+rxi(fi-Φ ) | Freelance ...   \n",
       "1735       Cirkuz Pol-Etik Et samfunds satirisk program   \n",
       "\n",
       "                    location  following  followers  totaltweets  retweetcount  \\\n",
       "0                        NaN       1228        521        34115             1   \n",
       "1                    Pangaea        515        536        39951            17   \n",
       "2                  København        972        947       231239            17   \n",
       "3          Nykøbing Sjælland       1292        346        21549            17   \n",
       "4         København, Danmark        111        269        21567             0   \n",
       "...                      ...        ...        ...          ...           ...   \n",
       "1731               København        511       2464        33254            28   \n",
       "1732                 Denmark       2249       2717        15616            28   \n",
       "1733      København, Danmark        612        624        12430            28   \n",
       "1734  Frederiksberg, Denmark        339       1089        44893             0   \n",
       "1735                     NaN        179          1           45             0   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Beder alle indberette dette tweet, da det tyde...   \n",
       "1     Få din vaccination uden tidsbestilling. Der er...   \n",
       "2     Få din vaccination uden tidsbestilling. Der er...   \n",
       "3     Få din vaccination uden tidsbestilling. Der er...   \n",
       "4     Indsatsen i Afghanistan har kostet Danmark 15 ...   \n",
       "...                                                 ...   \n",
       "1731  Israels massevaccination: \\n25% stigning i hje...   \n",
       "1732  Israels massevaccination: \\n25% stigning i hje...   \n",
       "1733  Israels massevaccination: \\n25% stigning i hje...   \n",
       "1734  @DRNyheder @tv2newsdk @moderna_tx @pfizer Jeg ...   \n",
       "1735  Kan man få en klima-vaccine?? Så er @Spolitik ...   \n",
       "\n",
       "                                               hashtags                 date  \n",
       "0                                                    []  2021-08-16 23:59:33  \n",
       "1                                                    []  2021-08-16 21:14:11  \n",
       "2                                                    []  2021-08-16 16:41:45  \n",
       "3                                                    []  2021-08-16 16:07:07  \n",
       "4                                ['dkpol', 'COVID19dk']  2021-08-16 15:48:37  \n",
       "...                                                 ...                  ...  \n",
       "1731                                                 []  2021-08-11 18:48:21  \n",
       "1732                                                 []  2021-08-11 17:59:14  \n",
       "1733  ['dkpol', 'dkmedier', 'coronadk', 'covid19dk',...  2021-08-11 17:50:59  \n",
       "1734                   ['dkpol', 'dkmedier', 'COVID19']  2021-08-10 19:29:12  \n",
       "1735  ['dkpol', 'dkmedier', 'COVID19dk', 'coronadk',...  2021-08-09 16:41:59  \n",
       "\n",
       "[1736 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('df1.csv')\n",
    "df2=pd.read_csv('df2.csv')\n",
    "df3=pd.read_csv('df3.csv')\n",
    "\n",
    "obs = [df1, df2, df3]\n",
    "\n",
    "data_set = pd.concat(obs)\n",
    "data_set = data_set.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62dd47",
   "metadata": {},
   "source": [
    "### Cleaning the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ae673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    " \n",
    "    stop_words = set(stopwords.words('danish'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "#after tweepy preprocessing the colon symbol left remain after      #removing mentions\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Ä¶', '', tweet)\n",
    "#replace consecutive non-ASCII characters with a space\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "#remove emojis from tweet\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "#filter using NLTK library append it to a string\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "#looping through conditions\n",
    "    for w in word_tokens:\n",
    "#check tokens against stop words , emoticons and punctuations\n",
    "        if w not in stop_words and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)\n",
    "    #print(word_tokens)\n",
    "    #print(filtered_sentence)return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "083d8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d5d059f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopord: Package 'stopord' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopord.txt', 'r') as f:\n",
    "    stopwords_danish = []\n",
    "    for line in f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a8634a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " \"'beder\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'alle\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'indberette\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'dette\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'tweet\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'da\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'det\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'tydeligt\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'opfordrer\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'til\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'overgreb\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'tvang\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'og\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'vold\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'mod\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'børn\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'og\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'unge\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '.',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'bør\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'ikke\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'høre\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'hjemme\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'på\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'sociale\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'medier\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '#',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'coronadk\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '#',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'dkmedier\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '#',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'dkpol\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '#',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'covid19dk\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '@',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'sstbrostrom\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '@',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'heunicke\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'hvad\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'er\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'det\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'for\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'nogle\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'monstre\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'har\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'skabt\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " '?',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'https\",\n",
       " \"'\",\n",
       " ',',\n",
       " \"'\",\n",
       " ':',\n",
       " \"'\",\n",
       " ',',\n",
       " \"'//t.co/ido6ezf2ec\",\n",
       " \"'\",\n",
       " ']']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specifying text column\n",
    "sentence = data_set1.text.values[0]\n",
    "\n",
    "sent = nltk.tokenize.word_tokenize(sentence)\n",
    "\n",
    "emoji = emoji_pattern.sub(r'', str(sent))\n",
    "\n",
    "text = emoji.lower()\n",
    "\n",
    "stop_words_list = nltk.corpus.stopwords.words(\"danish\")\n",
    "sent_sw_removed = [i for i in nltk.word_tokenize(text) if i not in stop_words_list]\n",
    "sent_sw_removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8667e6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Dropping collumns\n",
    "data_set1 = data_set.drop(['Unnamed: 0','username', 'description', 'followers', 'following'], axis=1).reset_index(drop = True)\n",
    "\n",
    "#Specifying text column\n",
    "sentence = data_set1.text.values\n",
    "\n",
    "#Filtering out emojis etc. using the function\n",
    "#tweet = emoji_pattern.sub(r'', str(sentence))\n",
    "\n",
    "#Tokenizing string objects\n",
    "\n",
    "#lwr_tweet = [nltk.word_tokenize(i.lower()) for i in data_set1.text.values]\n",
    "\n",
    "#Dropping stopwords\n",
    "\n",
    "#stop_words_list = nltk.corpus.stopwords.words(\"danish\")\n",
    "#sent_sw_removed = [i for i in tweet if i not in stop_words_list]\n",
    "#sent_sw_removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2f36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
